{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba44ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc93b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_creation(corpus, ngram_range=(1, 1)):\n",
    "    \"\"\"\n",
    "    Produces a range of ngrams in list-of-list format from a corpus.\n",
    "    \n",
    "    Parameters:\n",
    "    corpus (list): A list of document-length strings\n",
    "    \n",
    "    ngram_range (tuple): A tuple containing two integers. The first integer\n",
    "    should not be less than 1. The second integer must be greater-than or \n",
    "    equal-to the first.\n",
    "    \n",
    "    Returns:\n",
    "    ngram_list (list): A list-of-lists containing one or more nested lists.\n",
    "    The nested lists contain tuples of strings.\n",
    "    \"\"\"\n",
    "    \n",
    "    ngram_list = []\n",
    "    for i in range(ngram_range[0], ngram_range[1]+1):\n",
    "        output = [list(ngrams(note, i)) for note in corpus]\n",
    "        ngram_list.append(output)\n",
    "\n",
    "    return ngram_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d224df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_refinement(dataframe_list, ngram_range=(1,1)):\n",
    "    \"\"\"\n",
    "    Establishes a set of vocabulary tokens, eliminating repeated tokens.\n",
    "    \n",
    "    Parameters:\n",
    "    dataframe_list (list): A list containing dataframes separated by\n",
    "    classification\n",
    "    \n",
    "    ngram_range (tuple): A tuple containing two integers. The first integer\n",
    "    should not be less than 1. The second integer must be greater-than or \n",
    "    equal-to the first.\n",
    "    \n",
    "    Returns:\n",
    "    output_vocab (list): A list containing nested sets of vocabulary tokens.\n",
    "    \"\"\"\n",
    "    output_vocab = []\n",
    "    for df in dataframe_list:\n",
    "        for i in range(ngram_range[0], ngram_range[1] + 1):\n",
    "            vocab = set()\n",
    "            for row in df.itertuples():\n",
    "                for item in row[i+2]:\n",
    "                    vocab.add(item)\n",
    "            output_vocab.append(vocab)\n",
    "    return output_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_elements(list_of_lists: list):\n",
    "    \"\"\"\n",
    "    Reduces a list of vocab terms by removing tokens that a given \n",
    "    classification's vocab shares with another classification. Each nested\n",
    "    set of tokens is compared to every other set of tokens. The resulting\n",
    "    set of tokens is appended to a new list as to ensure that tokens within\n",
    "    a given set are the unique tokens that are only present in that \n",
    "    classification's vocab.\n",
    "    \n",
    "    Parameters:\n",
    "    list_of_lists (list): a list containing sets of vocabulary tokens,\n",
    "    separated by both classification and ngrams.\n",
    "    \n",
    "    Returns:\n",
    "    output_list (list): a list containing sets of vocabulary tokens,\n",
    "    but the number of tokens in each set has been reduced in number.\n",
    "    \"\"\"\n",
    "    \n",
    "    output_list = []\n",
    "    for i in range(len(list_of_lists)):\n",
    "        current_list = list_of_lists[i]\n",
    "        for cycled_list in list_of_lists:\n",
    "            if cycled_list != list_of_lists[i]:\n",
    "                current_list = [item for item in current_list if item not in cycled_list]\n",
    "        output_list.append(current_list)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309cffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vocab(vocab, ngram_range):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    new_vocab = []\n",
    "    for i in range(ngram_range[0], ngram_range[1] + 1):\n",
    "        new_vocab.append([])\n",
    "    for sublist in vocab:\n",
    "        for term in sublist:\n",
    "            new_vocab[len(term)-1].append(term)\n",
    "    return new_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(dataframe, vocab):\n",
    "    \"\"\"\n",
    "    Generates a bag-of-words model dataframe. The resulting \n",
    "    dataframe is a sparse matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    dataframe (pandas.DataFrame): A dataframe with columns\n",
    "    for tuples containing patient ID and note number, \n",
    "    manually annotated classification of the note, and a\n",
    "    document-length string of the content of those notes.\n",
    "    \n",
    "    vocab (list): a list containing sets of vocabulary tokens.\n",
    "    \n",
    "    Returns:\n",
    "    bow_model (pandas.Dataframe): a bag-of-words model \n",
    "    dataframe. The columns are denoted by the vocabulary \n",
    "    tokens while the rows are denoted by tuples \n",
    "    containing patient ID and note number. The values of\n",
    "    the matrix are counts of how many times a given token\n",
    "    occurred in the contents of the respective note.\n",
    "    \"\"\"\n",
    "\n",
    "    output = {}    \n",
    "    corpus_length = dataframe.shape[0]\n",
    "    for row in dataframe.itertuples():\n",
    "        id_note = str(row[0])\n",
    "        cls = str(row[1])\n",
    "            \n",
    "        if id_note not in output:\n",
    "            output[id_note] = {}\n",
    "        \n",
    "        for i in range(2, 5):\n",
    "            cnt = Count(row[i])\n",
    "            for term in vocab[i-2]:\n",
    "                ngram = str(term)\n",
    "                output[id_note][ngram] = cnt[term]\n",
    "                    \n",
    "        output[id_note]['--classification--'] = cls\n",
    "\n",
    "    bow_model = pd.DataFrame.from_dict(output, orient='index')\n",
    "    return bow_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
